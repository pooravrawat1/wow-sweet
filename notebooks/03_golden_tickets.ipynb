{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 — Golden Ticket Scoring | SweetReturns Golden City\n",
    "\n",
    "Implements the **5-tier Golden Ticket system** + **Platinum detection**.\n",
    "\n",
    "Each ticket is a binary signal based on quantitative thresholds derived from:\n",
    "- Historical drawdowns\n",
    "- Volume\n",
    "- Volatility\n",
    "- Skewness\n",
    "- Relative performance\n",
    "\n",
    "**Input:** `stock_features.parquet` (from notebook 02)\n",
    "\n",
    "**Output:** `stock_tickets.parquet` with Golden Score (0–5) and Platinum flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_parquet(\"stock_features.parquet\")\n",
    "print(f\"Loaded: {df.shape}, Tickers: {df['ticker'].nunique()}, Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket I — Dip Ticket (\"The Sour Candy Drop\")\n",
    "\n",
    "Qualifies when `drawdown_percentile > 0.80`.\n",
    "\n",
    "This catches stocks that are experiencing a historically deep dip relative to their own history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ticket_1_dip\"] = (df[\"drawdown_percentile\"] > 0.80).astype(int)\n",
    "print(f\"Ticket I (Dip) - qualifying: {df['ticket_1_dip'].sum()} / {len(df)} ({df['ticket_1_dip'].mean():.1%})\")\n",
    "print(f\"Unique tickers qualifying (ever): {df[df['ticket_1_dip']==1]['ticker'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket II — Shock Ticket (\"The Jawbreaker\")\n",
    "\n",
    "Qualifies when `drawdown_percentile > 0.85` AND `volume_percentile > 0.90` AND `vol_percentile > 0.85`.\n",
    "\n",
    "This catches violent dips with extreme volume — true \"jawbreaker\" events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ticket_2_shock\"] = (\n",
    "    (df[\"drawdown_percentile\"] > 0.85) &\n",
    "    (df[\"volume_percentile\"] > 0.90) &\n",
    "    (df[\"vol_percentile\"] > 0.85)\n",
    ").astype(int)\n",
    "print(f\"Ticket II (Shock) - qualifying: {df['ticket_2_shock'].sum()} / {len(df)} ({df['ticket_2_shock'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket III — Asymmetry Ticket (\"The Fortune Cookie\")\n",
    "\n",
    "Qualifies when deep dip + positive forward skew + outsized upside potential vs limited downside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward 60-day return\n",
    "df[\"fwd_60d_return\"] = df.groupby(\"ticker\")[\"Close\"].transform(\n",
    "    lambda x: x.shift(-60) / x - 1\n",
    ")\n",
    "\n",
    "# Forward 60-day skew (of daily returns over next 60 days)\n",
    "def compute_fwd_skew(group):\n",
    "    ret = group[\"daily_return\"].values\n",
    "    fwd_skew = np.full(len(ret), np.nan)\n",
    "    for i in range(len(ret) - 60):\n",
    "        window = ret[i+1:i+61]\n",
    "        valid = window[~np.isnan(window)]\n",
    "        if len(valid) >= 20:\n",
    "            fwd_skew[i] = stats.skew(valid)\n",
    "    group[\"fwd_60d_skew\"] = fwd_skew\n",
    "    return group\n",
    "\n",
    "df = df.groupby(\"ticker\", group_keys=False).apply(compute_fwd_skew)\n",
    "\n",
    "# Forward return distribution percentiles\n",
    "def compute_fwd_distribution(group):\n",
    "    ret = group[\"daily_return\"].values\n",
    "    p5 = np.full(len(ret), np.nan)\n",
    "    p25 = np.full(len(ret), np.nan)\n",
    "    median = np.full(len(ret), np.nan)\n",
    "    p75 = np.full(len(ret), np.nan)\n",
    "    p95 = np.full(len(ret), np.nan)\n",
    "    for i in range(len(ret) - 60):\n",
    "        window = ret[i+1:i+61]\n",
    "        valid = window[~np.isnan(window)]\n",
    "        if len(valid) >= 20:\n",
    "            p5[i] = np.percentile(valid, 5)\n",
    "            p25[i] = np.percentile(valid, 25)\n",
    "            median[i] = np.percentile(valid, 50)\n",
    "            p75[i] = np.percentile(valid, 75)\n",
    "            p95[i] = np.percentile(valid, 95)\n",
    "    group[\"fwd_p5\"] = p5\n",
    "    group[\"fwd_p25\"] = p25\n",
    "    group[\"fwd_median\"] = median\n",
    "    group[\"fwd_p75\"] = p75\n",
    "    group[\"fwd_p95\"] = p95\n",
    "    return group\n",
    "\n",
    "df = df.groupby(\"ticker\", group_keys=False).apply(compute_fwd_distribution)\n",
    "print(f\"Forward return features computed\")\n",
    "print(df[[\"fwd_60d_return\", \"fwd_60d_skew\", \"fwd_p5\", \"fwd_median\", \"fwd_p95\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median drawdown per ticker (for downside bound)\n",
    "median_drawdown = df.groupby(\"ticker\")[\"drawdown_pct\"].transform(\"median\").abs()\n",
    "\n",
    "df[\"ticket_3_asymmetry\"] = (\n",
    "    (df[\"drawdown_percentile\"] > 0.85) &\n",
    "    (df[\"fwd_60d_skew\"] > 0) &\n",
    "    (df[\"fwd_p95\"] > 2 * df[\"fwd_median\"].abs()) &\n",
    "    (df[\"fwd_p5\"] > -median_drawdown)\n",
    ").astype(int)\n",
    "print(f\"Ticket III (Asymmetry) - qualifying: {df['ticket_3_asymmetry'].sum()} / {len(df)} ({df['ticket_3_asymmetry'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket IV — Relative Dislocation Ticket (\"The Taffy Pull\")\n",
    "\n",
    "Qualifies when the stock has deeply underperformed SPY and shows mean-reverting behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative return history percentile 15 threshold\n",
    "rel_return_p15 = df.groupby(\"ticker\")[\"relative_return_vs_spy\"].transform(\n",
    "    lambda x: x.quantile(0.15)\n",
    ")\n",
    "\n",
    "# Mean reversion score: negative autocorrelation suggests mean-reverting\n",
    "df[\"ticket_4_dislocation\"] = (\n",
    "    (df[\"drawdown_percentile\"] > 0.80) &\n",
    "    (df[\"relative_return_vs_spy\"] < rel_return_p15) &\n",
    "    (df[\"autocorrelation_lag1\"] < -0.1)\n",
    ").astype(int)\n",
    "print(f\"Ticket IV (Dislocation) - qualifying: {df['ticket_4_dislocation'].sum()} / {len(df)} ({df['ticket_4_dislocation'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket V — Structural Convexity Ticket (\"The Golden Gummy Bear\")\n",
    "\n",
    "The rarest ticket — requires extreme drawdown + volume + underperformance + positive skew + favorable volatility regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Favorable volatility regime: VIX proxy - use realized vol of market\n",
    "favorable_vol = df[\"regime_label\"].isin([\"bull_quiet\", \"bear_quiet\"])\n",
    "\n",
    "df[\"ticket_5_convexity\"] = (\n",
    "    (df[\"drawdown_percentile\"] > 0.90) &\n",
    "    (df[\"volume_percentile\"] > 0.90) &\n",
    "    (df[\"relative_return_vs_spy\"] < rel_return_p15) &\n",
    "    (df[\"fwd_60d_skew\"] > 0.5) &\n",
    "    favorable_vol\n",
    ").astype(int)\n",
    "print(f\"Ticket V (Convexity) - qualifying: {df['ticket_5_convexity'].sum()} / {len(df)} ({df['ticket_5_convexity'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Golden Score: sum of 5 tickets (0-5)\n",
    "df[\"golden_score\"] = (\n",
    "    df[\"ticket_1_dip\"] + df[\"ticket_2_shock\"] + df[\"ticket_3_asymmetry\"] +\n",
    "    df[\"ticket_4_dislocation\"] + df[\"ticket_5_convexity\"]\n",
    ")\n",
    "\n",
    "# Rarity percentile: cross-sectional rank on each date\n",
    "df[\"rarity_percentile\"] = df.groupby(\"Date\")[\"golden_score\"].rank(pct=True)\n",
    "\n",
    "# Platinum: golden_score >= 4 AND rarity_percentile > 0.98 AND extreme conditions\n",
    "df[\"is_platinum\"] = (\n",
    "    (df[\"golden_score\"] >= 4) &\n",
    "    (df[\"rarity_percentile\"] > 0.98) &\n",
    "    (df[\"fwd_60d_skew\"] > 1.0) &\n",
    "    (df[\"relative_return_vs_spy\"] < df.groupby(\"ticker\")[\"relative_return_vs_spy\"].transform(lambda x: x.quantile(0.05))) &\n",
    "    df[\"regime_label\"].isin([\"bull_quiet\", \"bear_quiet\"])\n",
    ").astype(bool)\n",
    "\n",
    "print(f\"\\n=== Golden Score Distribution ===\")\n",
    "print(df[\"golden_score\"].value_counts().sort_index())\n",
    "print(f\"\\nPlatinum stores: {df['is_platinum'].sum()} events across {df[df['is_platinum']]['ticker'].nunique()} tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "fig.suptitle(\"Golden Ticket Distribution\", fontsize=14, color=\"#FFD700\")\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "# Score distribution\n",
    "score_counts = df.groupby(\"Date\")[\"golden_score\"].value_counts().unstack(fill_value=0).mean()\n",
    "colors = [\"#F5F5DC\", \"#7FFF00\", \"#00BFFF\", \"#FFD700\", \"#FF69B4\", \"#FF4500\"]\n",
    "axes[0].bar(score_counts.index, score_counts.values, color=colors[:len(score_counts)])\n",
    "axes[0].set_xlabel(\"Golden Score\")\n",
    "axes[0].set_ylabel(\"Avg stocks per day\")\n",
    "axes[0].set_title(\"Score Distribution\", color=\"#FFD700\")\n",
    "\n",
    "# Tickets over time\n",
    "monthly = df.set_index(\"Date\").resample(\"ME\")[[\"ticket_1_dip\", \"ticket_2_shock\", \"ticket_3_asymmetry\", \"ticket_4_dislocation\", \"ticket_5_convexity\"]].sum()\n",
    "monthly.plot(ax=axes[1], linewidth=1.5)\n",
    "axes[1].set_title(\"Ticket Activity Over Time\", color=\"#FFD700\")\n",
    "axes[1].legend(fontsize=7)\n",
    "\n",
    "# Platinum events\n",
    "plat_monthly = df[df[\"is_platinum\"]].set_index(\"Date\").resample(\"ME\").size()\n",
    "axes[2].bar(plat_monthly.index, plat_monthly.values, color=\"#DAA520\", width=25)\n",
    "axes[2].set_title(\"Platinum Events\", color=\"#FFD700\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"golden_tickets.png\", dpi=150, facecolor=\"#1a1a2e\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"stock_tickets.parquet\", index=False)\n",
    "print(f\"Saved stock_tickets.parquet: {df.shape}\")\n",
    "print(f\"Ready for 04_forward_returns.ipynb!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Ticket | Name | Key Condition | Rarity |\n",
    "|--------|------|---------------|--------|\n",
    "| I | Dip (Sour Candy Drop) | `drawdown_percentile > 0.80` | ~20% |\n",
    "| II | Shock (Jawbreaker) | Drawdown + Volume + Volatility | ~2-5% |\n",
    "| III | Asymmetry (Fortune Cookie) | Dip + Positive Skew + Upside | ~1-3% |\n",
    "| IV | Dislocation (Taffy Pull) | Underperformance + Mean Reversion | ~2-5% |\n",
    "| V | Convexity (Golden Gummy Bear) | Extreme Multi-Factor | <1% |\n",
    "\n",
    "**Golden Score** = sum of 5 binary tickets (0–5)\n",
    "\n",
    "**Platinum** = Golden Score >= 4 + top 2% rarity + extreme skew + deep underperformance + quiet regime\n",
    "\n",
    "**Next:** `04_forward_returns.ipynb` — analyze realized forward returns conditioned on ticket signals"
   ]
  }
 ]
}