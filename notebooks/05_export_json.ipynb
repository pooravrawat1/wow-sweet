{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 05 \u2014 Export JSON for Frontend\n",
        "**SweetReturns Golden City** data pipeline \u2014 **FINAL NOTEBOOK**\n",
        "\n",
        "This notebook reads all computed data from the pipeline and exports the JSON payload that the React frontend consumes.\n",
        "\n",
        "### Pipeline recap\n",
        "| # | Notebook | Output |\n",
        "|---|---|---|\n",
        "| 01 | EDA | `stock_data_clean.parquet` |\n",
        "| 02 | Feature Engineering | `stock_features.parquet`, `correlation_matrix.parquet` |\n",
        "| 03 | Golden Tickets | `stock_tickets.parquet`, `graph_features.parquet` |\n",
        "| 04 | Forward Returns | `stock_directions.parquet` |\n",
        "| **05** | **Export JSON** | **`frontend_payload.json`** |\n",
        "\n",
        "### Output schema\n",
        "```json\n",
        "{\n",
        "  \"generated_at\": \"2023-11-15\",\n",
        "  \"regime\": \"bull\",\n",
        "  \"stock_count\": 500,\n",
        "  \"stocks\": [ ... ],\n",
        "  \"correlation_edges\": [ ... ],\n",
        "  \"sectors\": [ ... ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "df = pd.read_parquet(\"stock_directions.parquet\")\n",
        "corr_matrix = pd.read_parquet(\"correlation_matrix.parquet\")\n",
        "graph_features = pd.read_parquet(\"graph_features.parquet\")\n",
        "print(f\"Loaded: {df.shape}\")\n",
        "print(f\"Correlation matrix: {corr_matrix.shape}\")\n",
        "print(f\"Graph features: {graph_features.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---- Latest-date snapshot ----\n",
        "# Take the most recent trading day per ticker.\n",
        "# If some tickers are missing on the very latest date,\n",
        "# fall back to their most recent available row.\n",
        "\n",
        "latest_date = df[\"Date\"].max()\n",
        "snapshot = df[df[\"Date\"] == latest_date].copy()\n",
        "\n",
        "# If some tickers are missing on the latest date, use their most recent available\n",
        "missing = set(df[\"ticker\"].unique()) - set(snapshot[\"ticker\"].unique())\n",
        "for ticker in missing:\n",
        "    ticker_data = df[df[\"ticker\"] == ticker].sort_values(\"Date\").iloc[-1:]\n",
        "    snapshot = pd.concat([snapshot, ticker_data])\n",
        "\n",
        "snapshot = snapshot.drop_duplicates(subset=\"ticker\", keep=\"last\")\n",
        "print(f\"Snapshot: {len(snapshot)} stocks as of {latest_date.date()}\")\n",
        "print(f\"Back-filled from earlier dates: {len(missing)} tickers\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---- Assign city grid positions by sector ----\n",
        "# Each sector occupies a SECTOR_SIZE x SECTOR_SIZE block on the XZ plane.\n",
        "# Within a sector, stocks are laid out in a grid sorted by golden_score.\n",
        "\n",
        "SECTORS = [\n",
        "    {\"name\": \"Technology\", \"position\": [0, 0], \"color\": \"#00BFFF\"},\n",
        "    {\"name\": \"Healthcare\", \"position\": [1, 0], \"color\": \"#FF69B4\"},\n",
        "    {\"name\": \"Financials\", \"position\": [2, 0], \"color\": \"#FFD700\"},\n",
        "    {\"name\": \"Consumer Discretionary\", \"position\": [0, 1], \"color\": \"#FF4500\"},\n",
        "    {\"name\": \"Communication Services\", \"position\": [1, 1], \"color\": \"#9370DB\"},\n",
        "    {\"name\": \"Industrials\", \"position\": [2, 1], \"color\": \"#7FFF00\"},\n",
        "    {\"name\": \"Consumer Staples\", \"position\": [0, 2], \"color\": \"#FFA500\"},\n",
        "    {\"name\": \"Energy\", \"position\": [1, 2], \"color\": \"#DC143C\"},\n",
        "    {\"name\": \"Utilities\", \"position\": [2, 2], \"color\": \"#40E0D0\"},\n",
        "    {\"name\": \"Real Estate\", \"position\": [0, 3], \"color\": \"#DDA0DD\"},\n",
        "    {\"name\": \"Materials\", \"position\": [1, 3], \"color\": \"#8B4513\"},\n",
        "]\n",
        "\n",
        "SECTOR_SIZE = 50\n",
        "sector_map = {s[\"name\"]: s for s in SECTORS}\n",
        "\n",
        "def assign_city_positions(snapshot):\n",
        "    positions = {}\n",
        "    for sector_info in SECTORS:\n",
        "        name = sector_info[\"name\"]\n",
        "        sx, sy = sector_info[\"position\"]\n",
        "        base_x = sx * SECTOR_SIZE - 75\n",
        "        base_z = sy * SECTOR_SIZE - 75\n",
        "\n",
        "        sector_stocks = snapshot[snapshot[\"sector\"] == name].sort_values(\n",
        "            \"golden_score\", ascending=False\n",
        "        )\n",
        "        n = len(sector_stocks)\n",
        "        cols = int(np.ceil(np.sqrt(n)))\n",
        "\n",
        "        for i, (idx, row) in enumerate(sector_stocks.iterrows()):\n",
        "            col = i % cols\n",
        "            row_num = i // cols\n",
        "            spacing = SECTOR_SIZE / (cols + 1)\n",
        "            x = base_x + (col + 1) * spacing\n",
        "            z = base_z + (row_num + 1) * spacing\n",
        "            positions[row[\"ticker\"]] = {\n",
        "                \"x\": round(float(x), 2),\n",
        "                \"y\": 0,\n",
        "                \"z\": round(float(z), 2),\n",
        "            }\n",
        "    return positions\n",
        "\n",
        "city_positions = assign_city_positions(snapshot)\n",
        "print(f\"Assigned positions to {len(city_positions)} stocks\")\n",
        "\n",
        "# Show a few examples\n",
        "for t in list(city_positions.keys())[:5]:\n",
        "    print(f\"  {t}: {city_positions[t]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---- Build stocks JSON array ----\n",
        "# Each stock entry follows the API schema consumed by the React frontend.\n",
        "\n",
        "stocks_json = []\n",
        "for _, row in snapshot.iterrows():\n",
        "    ticker = row[\"ticker\"]\n",
        "    pos = city_positions.get(ticker, {\"x\": 0, \"y\": 0, \"z\": 0})\n",
        "\n",
        "    stock = {\n",
        "        \"ticker\": ticker,\n",
        "        \"company\": row.get(\"company\", ticker),\n",
        "        \"sector\": row.get(\"sector\", \"Unknown\"),\n",
        "        \"golden_score\": int(row.get(\"golden_score\", 0)),\n",
        "        \"is_platinum\": bool(row.get(\"is_platinum\", False)),\n",
        "        \"ticket_levels\": {\n",
        "            \"dip_ticket\": bool(row.get(\"ticket_1_dip\", 0)),\n",
        "            \"shock_ticket\": bool(row.get(\"ticket_2_shock\", 0)),\n",
        "            \"asymmetry_ticket\": bool(row.get(\"ticket_3_asymmetry\", 0)),\n",
        "            \"dislocation_ticket\": bool(row.get(\"ticket_4_dislocation\", 0)),\n",
        "            \"convexity_ticket\": bool(row.get(\"ticket_5_convexity\", 0)),\n",
        "        },\n",
        "        \"direction_bias\": {\n",
        "            \"buy\": round(float(row.get(\"buy_pct\", 0.25)), 3),\n",
        "            \"call\": round(float(row.get(\"call_pct\", 0.25)), 3),\n",
        "            \"put\": round(float(row.get(\"put_pct\", 0.25)), 3),\n",
        "            \"short\": round(float(row.get(\"short_pct\", 0.25)), 3),\n",
        "        },\n",
        "        \"forward_return_distribution\": {\n",
        "            \"p5\": round(float(row.get(\"fwd_p5\", 0)), 4),\n",
        "            \"p25\": round(float(row.get(\"fwd_p25\", 0)), 4),\n",
        "            \"median\": round(float(row.get(\"fwd_median\", 0)), 4),\n",
        "            \"p75\": round(float(row.get(\"fwd_p75\", 0)), 4),\n",
        "            \"p95\": round(float(row.get(\"fwd_p95\", 0)), 4),\n",
        "        },\n",
        "        \"city_position\": pos,\n",
        "        \"store_dimensions\": {\n",
        "            \"width\": round(float(row.get(\"store_width\", 3)), 1),\n",
        "            \"height\": round(float(row.get(\"store_height\", 2)), 1),\n",
        "            \"depth\": round(float(row.get(\"store_depth\", 3)), 1),\n",
        "        },\n",
        "        \"brand_color\": sector_map.get(row.get(\"sector\"), {}).get(\"color\", \"#FFFFFF\"),\n",
        "        \"drawdown_current\": round(float(row.get(\"drawdown_pct\", 0)), 4),\n",
        "        \"volume_percentile\": round(float(row.get(\"volume_percentile\", 0.5)), 3),\n",
        "        \"volatility_percentile\": round(float(row.get(\"vol_percentile\", 0.5)), 3),\n",
        "        \"rarity_percentile\": round(float(row.get(\"rarity_percentile\", 0.5)), 3),\n",
        "    }\n",
        "    stocks_json.append(stock)\n",
        "\n",
        "print(f\"Built {len(stocks_json)} stock entries\")\n",
        "print(f\"\\nSample keys: {list(stocks_json[0].keys())}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---- Build correlation edges JSON ----\n",
        "# Only include edges where |weight| > threshold to keep\n",
        "# the payload size manageable for the frontend.\n",
        "\n",
        "edges_json = []\n",
        "threshold = 0.5\n",
        "tickers = corr_matrix.columns.tolist()\n",
        "for i, t1 in enumerate(tickers):\n",
        "    for j, t2 in enumerate(tickers):\n",
        "        if j > i:\n",
        "            w = float(corr_matrix.iloc[i, j])\n",
        "            if abs(w) > threshold:\n",
        "                edges_json.append({\n",
        "                    \"source\": t1,\n",
        "                    \"target\": t2,\n",
        "                    \"weight\": round(w, 4),\n",
        "                })\n",
        "\n",
        "print(f\"Correlation edges (|w| > {threshold}): {len(edges_json)}\")\n",
        "print(f\"Total possible pairs: {len(tickers) * (len(tickers) - 1) // 2}\")\n",
        "print(f\"Density: {len(edges_json) / (len(tickers) * (len(tickers) - 1) // 2) * 100:.1f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---- Build final payload and export ----\n",
        "\n",
        "payload = {\n",
        "    \"generated_at\": str(latest_date),\n",
        "    \"regime\": snapshot[\"regime_label\"].mode().iloc[0] if \"regime_label\" in snapshot.columns else \"unknown\",\n",
        "    \"stock_count\": len(stocks_json),\n",
        "    \"stocks\": stocks_json,\n",
        "    \"correlation_edges\": edges_json,\n",
        "    \"sectors\": SECTORS,\n",
        "}\n",
        "\n",
        "# Export JSON (pretty-printed)\n",
        "with open(\"frontend_payload.json\", \"w\") as f:\n",
        "    json.dump(payload, f, indent=2, default=str)\n",
        "\n",
        "# Also save a compact version\n",
        "with open(\"frontend_payload.min.json\", \"w\") as f:\n",
        "    json.dump(payload, f, separators=(\",\", \":\"), default=str)\n",
        "\n",
        "import os\n",
        "size_kb = os.path.getsize(\"frontend_payload.json\") / 1024\n",
        "print(f\"Exported frontend_payload.json: {size_kb:.1f} KB\")\n",
        "print(f\"Exported frontend_payload.min.json: {os.path.getsize('frontend_payload.min.json') / 1024:.1f} KB\")\n",
        "print(f\"\\nSample stock entry:\")\n",
        "print(json.dumps(stocks_json[0], indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ---- Optional: copy to project public folder ----\n",
        "# Uncomment to copy to your project's public folder:\n",
        "# import shutil\n",
        "# shutil.copy(\"frontend_payload.json\", \"/path/to/wow-street/public/data/frontend_payload.json\")\n",
        "print(\"Done! Copy frontend_payload.json to your project's public/data/ folder\")\n",
        "print(\"The React frontend will load this at /data/frontend_payload.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline Summary\n",
        "\n",
        "The SweetReturns Golden City data pipeline transforms raw OHLCV data into a structured JSON payload for an interactive 3D city visualization.\n",
        "\n",
        "### Notebook-by-notebook\n",
        "\n",
        "| # | Notebook | What it does | Key output |\n",
        "|---|---|---|---|\n",
        "| 01 | **EDA** | Downloads data, profiles 500 tickers, maps GICS sectors, plots distributions & correlations | `stock_data_clean.parquet` |\n",
        "| 02 | **Feature Engineering** | Computes rolling volatility, drawdowns, volume percentiles, forward returns, regime labels | `stock_features.parquet`, `correlation_matrix.parquet` |\n",
        "| 03 | **Golden Tickets** | Scores 5 ticket dimensions (dip, shock, asymmetry, dislocation, convexity), computes `golden_score`, flags platinum stocks, builds graph features | `stock_tickets.parquet`, `graph_features.parquet` |\n",
        "| 04 | **Forward Returns** | Assigns direction bias (buy/call/put/short), computes store dimensions & agent density | `stock_directions.parquet` |\n",
        "| 05 | **Export JSON** | Snapshots latest date, lays out the city grid, assembles full API payload | `frontend_payload.json` |\n",
        "\n",
        "### Frontend integration\n",
        "\n",
        "The React app expects `frontend_payload.json` at `/data/frontend_payload.json`. The payload includes:\n",
        "\n",
        "- **stocks[]** \u2014 each stock's score, tickets, direction bias, store geometry, brand color, and city position\n",
        "- **correlation_edges[]** \u2014 significant pairwise correlations rendered as connecting roads/pipes\n",
        "- **sectors[]** \u2014 sector metadata (name, grid position, color) for district labeling\n",
        "- **regime** \u2014 current market regime label for global theming\n",
        "\n",
        "### Reprocessing\n",
        "\n",
        "To refresh the data, re-run notebooks 01\u201305 in order. Only notebook 05 needs to be re-run if the pipeline logic hasn't changed and you just want a fresh date snapshot."
      ]
    }
  ]
}